#![recursion_limit = "1024"]

#[macro_use]
extern crate derive_new;
#[macro_use]
extern crate derive_setters;
#[macro_use]
extern crate log;
#[macro_use]
extern crate thiserror;

pub mod checksum;
mod range;
mod systems;

pub use self::systems::*;

use chrono::{DateTime, Utc};
use filetime::FileTime;
use futures::{
    channel::mpsc,
    stream::{self, StreamExt},
};
use hyper::{
    body::{Body, HttpBody},
    client::{connect::Connect, Client},
    header::{HeaderMap, HeaderValue},
    Method, Request, Response, StatusCode,
};
use numtoa::NumToA;
use std::{
    fmt::Debug,
    io,
    num::{NonZeroU16, NonZeroU32, NonZeroU64},
    path::Path,
    sync::{
        atomic::{AtomicBool, Ordering},
        Arc,
    },
    time::UNIX_EPOCH,
};
use tokio::{
    fs::{self, File},
    io::AsyncWriteExt,
};

pub type EventSender = mpsc::UnboundedSender<(Arc<Path>, FetchEvent)>;
pub type Output<T> = (Arc<Path>, Result<T, Error>);

/// An error from the asynchronous file fetcher.
#[derive(Debug, Error)]
pub enum Error {
    #[error("task was cancelled")]
    Cancelled,
    #[error("http client error")]
    Client(#[from] hyper::Error),
    #[error("unable to concatenate fetched parts")]
    Concatenate(#[source] io::Error),
    #[error("unable to create file")]
    FileCreate(#[source] io::Error),
    #[error("unable to set timestamp on {:?}", _0)]
    FileTime(Arc<Path>, #[source] io::Error),
    #[error("content length is an invalid range")]
    InvalidRange(#[source] io::Error),
    #[error("unable to remove file with bad metadata")]
    MetadataRemove(#[source] io::Error),
    #[error("destination has no file name")]
    Nameless,
    #[error("unable to open fetched part")]
    OpenPart(Arc<Path>, #[source] io::Error),
    #[error("destination lacks parent")]
    Parentless,
    #[error("connection timed out")]
    TimedOut,
    #[error("error writing to file")]
    Write(#[source] io::Error),
    #[error("failed to rename partial to destination")]
    Rename(#[source] io::Error),
    #[error("server responded with an error: {}", _0)]
    Status(StatusCode),
}

/// Information about a source being fetched.
#[derive(Debug, Setters)]
pub struct Source {
    /// URLs whereby the file can be found.
    #[setters(skip)]
    pub urls: Arc<[Box<str>]>,

    /// Where the file shall ultimately be fetched to.
    #[setters(skip)]
    pub dest: Arc<Path>,

    /// Optional location to store the partial file
    #[setters(strip_option)]
    #[setters(into)]
    pub part: Option<Arc<Path>>,
}

impl Source {
    pub fn new(urls: impl Into<Arc<[Box<str>]>>, dest: impl Into<Arc<Path>>) -> Self {
        Self { urls: urls.into(), dest: dest.into(), part: None }
    }
}

/// Events which are submitted by the fetcher.
#[derive(Debug)]
pub enum FetchEvent {
    /// Signals that this file was already fetched.
    AlreadyFetched,
    /// States that we know the length of the file being fetched.
    ContentLength(u64),
    /// Notifies that the file has been fetched.
    Fetched,
    /// Notifies that a file is being fetched.
    Fetching,
    /// Reports the amount of bytes that have been read for a file.
    Progress(usize),
    /// Reports that a part of a file is being fetched.
    PartFetching(u64),
    /// Reports that a part has been fetched.
    PartFetched(u64),
}

/// An asynchronous file fetcher for clients fetching files.
///
/// The futures generated by the fetcher are compatible with single and multi-threaded
/// runtimes, allowing you to choose between the runtime that works best for your
/// application. A single-threaded runtime is generally recommended for fetching files,
/// as your network connection is unlikely to be faster than a single CPU core.
#[derive(new, Setters)]
pub struct Fetcher<C> {
    #[setters(skip)]
    client: Client<C, Body>,

    /// When set, cancels any active operations.
    #[new(default)]
    #[setters(strip_option)]
    cancel: Option<Arc<AtomicBool>>,

    /// The number of concurrent connections to sustain per file being fetched.
    #[new(default)]
    connections_per_file: Option<NonZeroU16>,

    /// The number of attempts to make when a request fails.
    #[new(value = "unsafe { NonZeroU16::new_unchecked(3) } ")]
    retries: NonZeroU16,

    /// The maximum size of a part file when downloading in parts.
    #[new(value = "unsafe { NonZeroU32::new_unchecked(2 * 1024 * 1024) }")]
    max_part_size: NonZeroU32,

    /// Holds a sender for submitting events to.
    #[new(default)]
    #[setters(into)]
    #[setters(strip_option)]
    events: Option<Arc<EventSender>>,
}

impl<C: Connect + Clone + Send + Sync + 'static> Fetcher<C> {
    /// Wraps the fetcher in an Arc.
    pub fn into_arc(self) -> Arc<Self> {
        Arc::new(self)
    }

    /// Request a file from one or more URIs.
    ///
    /// At least one URI must be provided as a source for the file. Each additional URI
    /// serves as a mirror for failover and load-balancing purposes.
    pub async fn request(
        self: Arc<Self>,
        uris: Arc<[Box<str>]>,
        to: Arc<Path>,
    ) -> Result<(), Error> {
        match self.clone().inner_request(uris.clone(), to.clone()).await {
            Ok(()) => Ok(()),
            Err(mut why) => {
                for _ in 1..self.retries.get() {
                    match self.clone().inner_request(uris.clone(), to.clone()).await {
                        Ok(()) => return Ok(()),
                        Err(cause) => why = cause,
                    }
                }

                Err(why)
            }
        }
    }

    async fn inner_request(
        self: Arc<Self>,
        uris: Arc<[Box<str>]>,
        to: Arc<Path>,
    ) -> Result<(), Error> {
        let mut modified = None;
        let mut length = None;
        let mut if_modified_since = None;

        // If the file already exists, validate that it is the same.
        if to.exists() {
            if let Some(response) = self.head(&*uris[0]).await? {
                let headers = &(response.headers());
                let content_length = content_length(headers);
                modified = last_modified(headers);

                if let (Some(content_length), Some(last_modified)) =
                    (content_length, modified)
                {
                    match fs::metadata(to.as_ref()).await {
                        Ok(metadata) => {
                            let modified = metadata.modified().map_err(Error::Write)?;
                            let ts = modified
                                .duration_since(UNIX_EPOCH)
                                .expect("time went backwards");

                            if metadata.len() == content_length
                                && ts.as_secs() == last_modified.timestamp() as u64
                            {
                                self.send((to, FetchEvent::AlreadyFetched));
                                return Ok(());
                            }

                            if_modified_since =
                                Some(DateTime::<Utc>::from(modified).to_rfc2822());
                            length = Some(content_length);
                        }
                        Err(why) => {
                            error!("failed to fetch metadata of {:?}: {}", to, why);
                            fs::remove_file(to.as_ref())
                                .await
                                .map_err(Error::MetadataRemove)?;
                        }
                    }
                }
            }
        }

        // If set, this will use multiple connections to download a file in parts.
        if let Some(connections) = self.connections_per_file {
            if let Some(response) = self.head(&*uris[0]).await? {
                let headers = &(response.headers());
                modified = last_modified(headers);
                let length = match length {
                    Some(length) => Some(length),
                    None => content_length(headers),
                };

                if let Some(length) = length {
                    if self.supports_range(&*uris[0], length).await? {
                        self.send((to.clone(), FetchEvent::ContentLength(length)));

                        return self
                            .get_many(length, connections.get(), uris, to, modified)
                            .await;
                    }
                }
            }
        }

        let mut request = Request::builder()
            .method(Method::GET) //
            .uri(&*uris[0]) //
            .header("Expect", "");

        if let Some(modified_since) = if_modified_since {
            request = request.header("if-modified-since", modified_since);
        }

        let request = request.body(Body::empty()).unwrap();

        let path =
            match self.get(&mut modified, request, to.clone(), to.clone(), None).await {
                Ok(path) => path,
                // Server does not support if-modified-since
                Err(Error::Status(StatusCode::NOT_IMPLEMENTED)) => {
                    let request = Request::builder()
                        .method(Method::GET) //
                        .uri(&*uris[0]) //
                        .header("Expect", "") //
                        .body(Body::empty())
                        .unwrap();

                    self.get(&mut modified, request, to.clone(), to, None).await?
                }
                Err(why) => return Err(why),
            };

        if let Some(modified) = modified {
            let filetime = FileTime::from_unix_time(modified.timestamp(), 0);
            filetime::set_file_times(&path, filetime, filetime)
                .map_err(move |why| Error::FileTime(path, why))?;
        }

        Ok(())
    }

    async fn get(
        &self,
        modified: &mut Option<DateTime<Utc>>,
        request: Request<Body>,
        to: Arc<Path>,
        dest: Arc<Path>,
        length: Option<u64>,
    ) -> Result<Arc<Path>, Error> {
        let mut file = File::create(to.as_ref()).await.map_err(Error::FileCreate)?;

        if let Some(length) = length {
            file.set_len(length).await.map_err(Error::Write)?;
        }

        let response = &mut validate(self.client.request(request).await?)?;

        if modified.is_none() {
            *modified = last_modified(&(response.headers()));
        }

        if response.status() == StatusCode::NOT_MODIFIED {
            return Ok(to);
        }

        while let Some(chunk) = response.body_mut().data().await {
            if self.cancelled() {
                return Err(Error::Cancelled);
            }

            let chunk = chunk?;

            self.send((dest.clone(), FetchEvent::Progress(chunk.len())));

            file.write_all(&chunk).await.map_err(Error::Write)?;
        }

        Ok(to)
    }

    async fn get_many(
        self: Arc<Self>,
        length: u64,
        concurrent: u16,
        uris: Arc<[Box<str>]>,
        to: Arc<Path>,
        mut modified: Option<DateTime<Utc>>,
    ) -> Result<(), Error> {
        let parent = to.parent().ok_or(Error::Parentless)?;
        let filename = to.file_name().ok_or(Error::Nameless)?;

        let mut buf = [0u8; 20];

        // The destination which parts will be concatenated to.
        let concatenated_file =
            &mut File::create(to.as_ref()).await.map_err(Error::FileCreate)?;

        let max_part_size =
            unsafe { NonZeroU64::new_unchecked(u64::from(self.max_part_size.get())) };

        let to_ = to.clone();
        let parts = stream::iter(range::generate(length, max_part_size).enumerate())
            // Generate a future for fetching each part that a range describes.
            .map(move |(partn, (range_start, range_end))| {
                let uri = uris[partn % uris.len()].clone();

                let part_path = {
                    let mut new_filename = filename.to_os_string();
                    new_filename
                        .push(&[".part", partn.numtoa_str(10, &mut buf)].concat());
                    parent.join(new_filename)
                };

                let fetcher = self.clone();
                let to = to_.clone();

                async move {
                    let range = range::to_string(range_start, range_end);

                    fetcher.send((to.clone(), FetchEvent::PartFetching(partn as u64)));

                    let request = Request::builder()
                        .method(Method::GET) //
                        .uri(&*uri) //
                        .header("range", range) //
                        .header("Expect", "") //
                        .body(Body::empty())
                        .unwrap();

                    let result = fetcher
                        .get(
                            &mut modified,
                            request,
                            part_path.into(),
                            to.clone(),
                            Some(range_end - range_start),
                        )
                        .await;

                    fetcher.send((to, FetchEvent::PartFetched(partn as u64)));

                    result
                }
            })
            // Ensure that only this many connections are happenning concurrently at a
            // time
            .buffered(concurrent as usize)
            // This type exploded the stack, and therefore needs to be boxed
            .boxed_local();

        systems::concatenator(concatenated_file, parts).await?;

        if let Some(modified) = modified {
            let filetime = FileTime::from_unix_time(modified.timestamp(), 0);
            filetime::set_file_times(&to, filetime, filetime)
                .map_err(|why| Error::FileTime(to, why))?;
        }

        Ok(())
    }

    async fn head(&self, uri: &str) -> Result<Option<Response<Body>>, Error> {
        let request = Request::builder()
            .method(Method::HEAD) //
            .uri(uri) //
            .header("Expect", "") //
            .body(Body::empty())
            .unwrap();

        match validate(self.client.request(request).await?).map(Some) {
            result @ Ok(_) => result,
            Err(Error::Status(StatusCode::NOT_IMPLEMENTED)) => Ok(None),
            Err(other) => Err(other),
        }
    }

    async fn supports_range(&self, uri: &str, length: u64) -> Result<bool, Error> {
        let request = Request::builder()
            .method(Method::HEAD) //
            .uri(uri) //
            .header("Expect", "") //
            .header("range", range::to_string(0, length)) //
            .body(Body::empty())
            .unwrap();

        let response = self.client.request(request).await?;

        if response.status() == StatusCode::PARTIAL_CONTENT {
            Ok(true)
        } else {
            validate(response).map(|_| false)
        }
    }

    fn cancelled(&self) -> bool {
        self.cancel.as_ref().map_or(false, |cancel| cancel.load(Ordering::SeqCst))
    }

    fn send(&self, event: (Arc<Path>, FetchEvent)) {
        if let Some(sender) = self.events.as_ref() {
            let _ = sender.unbounded_send(event);
        }
    }
}

fn content_length(headers: &HeaderMap<HeaderValue>) -> Option<u64> {
    headers
        .get("content-length")
        .and_then(|header| header.to_str().ok())
        .and_then(|header| header.parse::<u64>().ok())
}

fn last_modified(headers: &HeaderMap<HeaderValue>) -> Option<DateTime<Utc>> {
    headers
        .get("last-modified")
        .and_then(|header| header.to_str().ok())
        .and_then(|header| DateTime::parse_from_rfc2822(header).ok())
        .map(|tz| tz.with_timezone(&Utc))
}

fn validate(response: Response<Body>) -> Result<Response<Body>, Error> {
    let status = response.status();

    if status.as_u16() < 300 {
        Ok(response)
    } else {
        Err(Error::Status(status))
    }
}
